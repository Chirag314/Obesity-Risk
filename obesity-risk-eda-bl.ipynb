{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/cid007/obesity-risk-eda-bl?scriptVersionId=162017463\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-05T22:05:01.504424Z","iopub.execute_input":"2024-02-05T22:05:01.504818Z","iopub.status.idle":"2024-02-05T22:05:02.690112Z","shell.execute_reply.started":"2024-02-05T22:05:01.504784Z","shell.execute_reply":"2024-02-05T22:05:02.688993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n## ðŸš€ Getting Started\nIn this binary classification task focused on predicting obesity risk in individuals, which is related to cardiovascular disease.\n\n## ðŸ”§ Tools and Libraries\n\nWe will be using Python for this project, along with several libraries for data analysis and machine learning. Here are the main libraries we'll be using:\n\n- **Pandas**: For data manipulation and analysis.\n- **NumPy**: For numerical computations.\n- **Matplotlib and Seaborn**: For data visualization.\n- **Scikit-learn**: For machine learning tasks, including data preprocessing, model training, and model evaluation.\n- **Gradient Boosting (e.g., XGBoost, LightGBM)**: Ensemble method building decision trees sequentially,Often yields high predictive performance.\nHandles complex relationships and feature interactions.\n\n## ðŸ“ˆ Workflow\n\nHere's a brief overview of our workflow for this project:\n\n1. **Data Loading and Preprocessing**: Load the data and preprocess it for analysis and modeling. This includes handling missing values, encoding categorical variables, and scaling numerical variables..\n\n2. **Exploratory Data Analysis (EDA)**: Explore the data to gain insights and understand the relationships between different **`features`** and the .\n\n3. **Model Training**: Train the model on the preprocessed data.\n\n4. **Model Evaluation**: Evaluate the model's performance using various metrics, such as accuracy, precision, recall, F1-score, Cohen's Kappa, and Matthews Correlation Coefficient.\n\n5. **Error Analysis**: Analyze the instances where the model made errors to gain insights into potential improvements.\n\n6. **Future Work**: Based on our findings, suggest potential directions for future work.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n    \n# <span style=\"color:#094863; font-size: 1%|;\">Loading Libraries</span>","metadata":{}},{"cell_type":"code","source":"# Data Manipulation and Analysis\nimport pandas as pd\nimport numpy as np\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Utilities\nimport pprint\nimport warnings\n\n# Data Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, QuantileTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics, linear_model, tree, naive_bayes,neighbors, ensemble, neural_network, svm\n\n# Feature Selection\nfrom sklearn.feature_selection import mutual_info_classif\n\n\n# Model Building\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\n\n# Cross validation\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, cross_val_predict\n\n# Statistical Analysis\nfrom scipy.stats import chi2_contingency\n\n# Hyperparameter Tuning\nimport optuna\n\n# Data Splitting\nfrom sklearn.model_selection import train_test_split\n\n# Metrices\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\ndef set_color_map(color_list):\n    cmap_custom = ListedColormap(color_list)\n    print(\"Notebook Color Schema:\")\n    sns.palplot(sns.color_palette(color_list))\n    plt.show()\n    return cmap_custom\n\ncolor_list = ['royalblue', 'cyan','yellow', 'orange']\ncmap_custom = set_color_map(color_list)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:02.691845Z","iopub.execute_input":"2024-02-05T22:05:02.692769Z","iopub.status.idle":"2024-02-05T22:05:08.556154Z","shell.execute_reply.started":"2024-02-05T22:05:02.692731Z","shell.execute_reply":"2024-02-05T22:05:08.555232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install catboost","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:08.561109Z","iopub.execute_input":"2024-02-05T22:05:08.561749Z","iopub.status.idle":"2024-02-05T22:05:24.918742Z","shell.execute_reply.started":"2024-02-05T22:05:08.561716Z","shell.execute_reply":"2024-02-05T22:05:24.917204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:24.922367Z","iopub.execute_input":"2024-02-05T22:05:24.922754Z","iopub.status.idle":"2024-02-05T22:05:25.154638Z","shell.execute_reply.started":"2024-02-05T22:05:24.922719Z","shell.execute_reply":"2024-02-05T22:05:25.153421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ignore warnings\nwarnings.filterwarnings(\"ignore\", category= UserWarning)\noptuna.logging.set_verbosity(optuna.logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.157241Z","iopub.execute_input":"2024-02-05T22:05:25.157634Z","iopub.status.idle":"2024-02-05T22:05:25.163226Z","shell.execute_reply.started":"2024-02-05T22:05:25.157602Z","shell.execute_reply":"2024-02-05T22:05:25.161867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the style\nrc = {\n    \"axes.facecolor\": \"#dcf5f7\",\n    \"figure.facecolor\": \"#dcf5f7\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#094863\",\n    \"font.family\": \"arial\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4,\n}\nsns.set(rc=rc)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.164874Z","iopub.execute_input":"2024-02-05T22:05:25.165269Z","iopub.status.idle":"2024-02-05T22:05:25.1777Z","shell.execute_reply.started":"2024-02-05T22:05:25.165236Z","shell.execute_reply":"2024-02-05T22:05:25.176421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n# <span style=\"color:#094863; font-size: 1%|;\"> Import Data and Exploration</span>","metadata":{}},{"cell_type":"code","source":"# import the csv files\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e2/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e2/test.csv')\nsubmission=pd.read_csv('/kaggle/input/playground-series-s4e2/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.179575Z","iopub.execute_input":"2024-02-05T22:05:25.180548Z","iopub.status.idle":"2024-02-05T22:05:25.397294Z","shell.execute_reply.started":"2024-02-05T22:05:25.180503Z","shell.execute_reply":"2024-02-05T22:05:25.395945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=train.copy()\ntest_df=test.copy()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.399031Z","iopub.execute_input":"2024-02-05T22:05:25.39937Z","iopub.status.idle":"2024-02-05T22:05:25.406639Z","shell.execute_reply.started":"2024-02-05T22:05:25.399343Z","shell.execute_reply":"2024-02-05T22:05:25.405744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.411914Z","iopub.execute_input":"2024-02-05T22:05:25.412548Z","iopub.status.idle":"2024-02-05T22:05:25.42049Z","shell.execute_reply.started":"2024-02-05T22:05:25.412514Z","shell.execute_reply":"2024-02-05T22:05:25.419066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.421783Z","iopub.execute_input":"2024-02-05T22:05:25.422163Z","iopub.status.idle":"2024-02-05T22:05:25.4583Z","shell.execute_reply.started":"2024-02-05T22:05:25.422131Z","shell.execute_reply":"2024-02-05T22:05:25.457236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.460043Z","iopub.execute_input":"2024-02-05T22:05:25.460415Z","iopub.status.idle":"2024-02-05T22:05:25.508354Z","shell.execute_reply.started":"2024-02-05T22:05:25.46037Z","shell.execute_reply":"2024-02-05T22:05:25.506553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.509993Z","iopub.execute_input":"2024-02-05T22:05:25.510372Z","iopub.status.idle":"2024-02-05T22:05:25.541927Z","shell.execute_reply.started":"2024-02-05T22:05:25.510338Z","shell.execute_reply":"2024-02-05T22:05:25.540743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the function that creates missing value heatmap\ndef plot_missing_data(dataset, title):\n  fig,ax=plt.subplots(figsize=(5,5))\n  plt.title(title)\n  sns.heatmap(dataset,cbar=False)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.54324Z","iopub.execute_input":"2024-02-05T22:05:25.543607Z","iopub.status.idle":"2024-02-05T22:05:25.54982Z","shell.execute_reply.started":"2024-02-05T22:05:25.543575Z","shell.execute_reply":"2024-02-05T22:05:25.548644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_missing_data(train_df.isnull(),\"Training Data\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:25.55147Z","iopub.execute_input":"2024-02-05T22:05:25.551835Z","iopub.status.idle":"2024-02-05T22:05:27.069316Z","shell.execute_reply.started":"2024-02-05T22:05:25.551804Z","shell.execute_reply":"2024-02-05T22:05:27.068146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_missing_data(test_df.isnull(),\"Test Data\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:27.070511Z","iopub.execute_input":"2024-02-05T22:05:27.070819Z","iopub.status.idle":"2024-02-05T22:05:28.146433Z","shell.execute_reply.started":"2024-02-05T22:05:27.070792Z","shell.execute_reply":"2024-02-05T22:05:28.145237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### It seems like there are no missing values in both train and test data.","metadata":{}},{"cell_type":"code","source":"# Check duplicate values\ntrain_df.duplicated().sum(), test_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.147888Z","iopub.execute_input":"2024-02-05T22:05:28.148592Z","iopub.status.idle":"2024-02-05T22:05:28.197721Z","shell.execute_reply.started":"2024-02-05T22:05:28.148559Z","shell.execute_reply":"2024-02-05T22:05:28.196648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### It seems like there are no duplicate values in both train and test data.","metadata":{}},{"cell_type":"code","source":"train_df.drop(['id'],axis=1).describe().T.style.bar(subset=['mean'],color='#7BCC70')\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.199529Z","iopub.execute_input":"2024-02-05T22:05:28.199874Z","iopub.status.idle":"2024-02-05T22:05:28.315648Z","shell.execute_reply.started":"2024-02-05T22:05:28.199847Z","shell.execute_reply":"2024-02-05T22:05:28.314469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe(include=\"object\").T.style.bar(subset=['unique'],color='#7BCC70')\\\n    .background_gradient(subset=['freq'], cmap='Reds')\\\n   ","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.317368Z","iopub.execute_input":"2024-02-05T22:05:28.317863Z","iopub.status.idle":"2024-02-05T22:05:28.403665Z","shell.execute_reply.started":"2024-02-05T22:05:28.317807Z","shell.execute_reply":"2024-02-05T22:05:28.402711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"string_columns=[f for f in train_df.columns if train_df[f].dtype == object and f != 'NObeyesdad']\nnumeric_columns=[f for f in train_df.columns if f not in string_columns and f not in ['id', 'NObeyesdad']]\nprint(string_columns)\nprint(numeric_columns)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.405029Z","iopub.execute_input":"2024-02-05T22:05:28.405339Z","iopub.status.idle":"2024-02-05T22:05:28.413765Z","shell.execute_reply.started":"2024-02-05T22:05:28.405313Z","shell.execute_reply":"2024-02-05T22:05:28.412506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unique_values(data):\n    total = data.count()\n    unq = pd.DataFrame(total)\n    unq.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n        type=data[col].dtype\n    unq['Uniques'] = uniques\n    return(np.transpose(unq))","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.415168Z","iopub.execute_input":"2024-02-05T22:05:28.415508Z","iopub.status.idle":"2024-02-05T22:05:28.423754Z","shell.execute_reply.started":"2024-02-05T22:05:28.415478Z","shell.execute_reply":"2024-02-05T22:05:28.422607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values(train_df[string_columns])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.425011Z","iopub.execute_input":"2024-02-05T22:05:28.425345Z","iopub.status.idle":"2024-02-05T22:05:28.480114Z","shell.execute_reply.started":"2024-02-05T22:05:28.425316Z","shell.execute_reply":"2024-02-05T22:05:28.478927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check categories for each categorical attribute\npd.set_option('display.max_colwidth',0)\ncat=[]\nfor col in string_columns:\n    catlist=train_df[col].value_counts().index.to_list()\n    cat.append([col,catlist])\npd.DataFrame(cat,columns=['Column Name','Categories']).set_index('Column Name').rename_axis(None)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.481902Z","iopub.execute_input":"2024-02-05T22:05:28.482627Z","iopub.status.idle":"2024-02-05T22:05:28.529256Z","shell.execute_reply.started":"2024-02-05T22:05:28.482578Z","shell.execute_reply":"2024-02-05T22:05:28.528124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n# <span style=\"color:#094863; font-size: 1%|;\"> Exploratory Data Analysis </span>","metadata":{}},{"cell_type":"code","source":"# LEts check correlation matric to find out which features are important in prediction survival\n\ncorrMatrix = train_df[numeric_columns].corr()\nsns.heatmap(corrMatrix, annot=True,cmap='RdYlGn')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:28.531269Z","iopub.execute_input":"2024-02-05T22:05:28.531631Z","iopub.status.idle":"2024-02-05T22:05:29.102928Z","shell.execute_reply.started":"2024-02-05T22:05:28.531585Z","shell.execute_reply":"2024-02-05T22:05:29.102015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n<strong>1. Weight is strongly corelated to Age,Height,FCVC and CH2O. Using feature engineering, we can derive new features from these three or drop some and check the results.</strong><br>\n<strong>2. Age is inversly co related with FAF. </strong><br>\n<strong>3. All these co relation canbe further checked by plotting scatter plot of related variables.</strong>","metadata":{}},{"cell_type":"code","source":"# Check distribution of numeric features\nimport matplotlib.pyplot as plt\nfig,axe=plt.subplots(nrows=4,ncols=2,figsize=(20,20),)\naxe=axe.flatten()\nsns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\naxis_counter=0\nfor feature in numeric_columns:\n  ax=axe[axis_counter]\n  _=sns.histplot(data=train_df,x=feature,kde=True,ax=ax)\n  _=ax.set_title(\"{}\".format(feature))\n  _=ax.set_ylabel(\"\")\n  _=ax.set_xlabel(\"\")\n  axis_counter+=1","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:29.104482Z","iopub.execute_input":"2024-02-05T22:05:29.10482Z","iopub.status.idle":"2024-02-05T22:05:34.242848Z","shell.execute_reply.started":"2024-02-05T22:05:29.10479Z","shell.execute_reply":"2024-02-05T22:05:34.241649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n<strong> 1. Age , height and weight are not normaly distributed, they need to be conveted to normal distribution.</strong><br>\n<strong> 2. Other numeric features require feature engineering and further probing. Binning might be one of the options.</strong>","metadata":{}},{"cell_type":"code","source":"# Check categorical features.\ndef plot_categorical_variables(df):\n    for column in df.columns:\n        if df[column].dtype == 'object' or len(df[column].unique()) < 10:\n            plt.figure(figsize=(12, 6))\n            sns.countplot(x=column, data=df,palette='rainbow')\n            plt.title(f'Distribution of {column}')\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:34.244479Z","iopub.execute_input":"2024-02-05T22:05:34.24553Z","iopub.status.idle":"2024-02-05T22:05:34.25327Z","shell.execute_reply.started":"2024-02-05T22:05:34.245488Z","shell.execute_reply":"2024-02-05T22:05:34.251993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_categorical_variables(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:34.25507Z","iopub.execute_input":"2024-02-05T22:05:34.255483Z","iopub.status.idle":"2024-02-05T22:05:37.023502Z","shell.execute_reply.started":"2024-02-05T22:05:34.25545Z","shell.execute_reply":"2024-02-05T22:05:37.022331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are seven categories of obesity risk. They seem to be kind of evenly distributed so this can be considered as balanced data.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n# <span style=\"color:#094863; font-size: 1%|;\"> Target Feature Distribution</span>","metadata":{}},{"cell_type":"code","source":"train_df['NObeyesdad'].value_counts(normalize=True).plot.bar(figsize=(12,6))\nplt.xlabel('Variables')\nplt.ylabel('Number of unique categories')\nplt.title('Total number of labels')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:37.032389Z","iopub.execute_input":"2024-02-05T22:05:37.033367Z","iopub.status.idle":"2024-02-05T22:05:37.419807Z","shell.execute_reply.started":"2024-02-05T22:05:37.033318Z","shell.execute_reply":"2024-02-05T22:05:37.418709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems there is not much difference between categories. They are sort of evenly distributed.","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#094863; font-size: 1%|;\"> Train/Test distribution Check</span>\n\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n<strong>To check weather train and test data came from same distribution, we combine train and test data and added one feature to denote each.\nAfter that we have plotted each varible with hue being train or test type. </strong>\n","metadata":{}},{"cell_type":"code","source":"train_df['Data Type']='Train'\ntest_df['Data Type']='Test'\n\nall=pd.concat([train_df.drop(['NObeyesdad'],axis=1),test_df],ignore_index=True)\nall.shape\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:37.421155Z","iopub.execute_input":"2024-02-05T22:05:37.421516Z","iopub.status.idle":"2024-02-05T22:05:37.440555Z","shell.execute_reply.started":"2024-02-05T22:05:37.421488Z","shell.execute_reply":"2024-02-05T22:05:37.439312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:37.441886Z","iopub.execute_input":"2024-02-05T22:05:37.442253Z","iopub.status.idle":"2024-02-05T22:05:37.469706Z","shell.execute_reply.started":"2024-02-05T22:05:37.442222Z","shell.execute_reply":"2024-02-05T22:05:37.468484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check numeric features\nplt.figure(figsize=(10,4*len(numeric_columns)))\nfor i, f in enumerate(numeric_columns,1):\n    plt.subplot(len(numeric_columns),1,i)\n    sns.histplot(data=all,x=f,hue='Data Type',kde=True,element='step',stat='density',common_norm=False,palette='bright')\n    plt.title(f'Distribution of {f} by Data Type')\n    #plt.xlabel('')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:37.471494Z","iopub.execute_input":"2024-02-05T22:05:37.471902Z","iopub.status.idle":"2024-02-05T22:05:44.356087Z","shell.execute_reply.started":"2024-02-05T22:05:37.47187Z","shell.execute_reply":"2024-02-05T22:05:44.355138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n## <span style=\"color:#094863; font-size: 1%|;\"> Train/Test categorical features check</span>\n","metadata":{}},{"cell_type":"code","source":"#Plot categorical features\nplt.figure(figsize=(10,4*len(string_columns)))\nfor i , f in enumerate(string_columns,1):\n    plt.subplot(len(string_columns),1,i)\n    sns.countplot(data=all,x=f,hue='Data Type',palette = 'pastel')\n    plt.title(f'Distribution of {f} by Data Type')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:44.35723Z","iopub.execute_input":"2024-02-05T22:05:44.358072Z","iopub.status.idle":"2024-02-05T22:05:47.388605Z","shell.execute_reply.started":"2024-02-05T22:05:44.358034Z","shell.execute_reply":"2024-02-05T22:05:47.387417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n<strong> It seems from above graphs that train and test features follow same distribution, so they are from same data.","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#094863; font-size: 1%|;\"> Prepare Data For Modelling</span>","metadata":{}},{"cell_type":"code","source":"category_mapping={\n    'Obesity_Type_III':0,\n    'Obesity_Type_II':1,\n    'Normal_Weight':2,\n    'Obesity_Type_I':3,\n    'Insufficient_Weight':4,\n    'Overweight_Level_II':5,\n    'Overweight_Level_I':6,    \n}\ntrain_df['y']=train_df['NObeyesdad'].map(category_mapping)\ntrain_df['y'].head()\ntrain_df.drop(['Data Type'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.389978Z","iopub.execute_input":"2024-02-05T22:05:47.390437Z","iopub.status.idle":"2024-02-05T22:05:47.429696Z","shell.execute_reply.started":"2024-02-05T22:05:47.390382Z","shell.execute_reply":"2024-02-05T22:05:47.428547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add ordinal features \ndef ord_feature(df):\n    df['Age_Cat'] = pd.cut(df['Age'], bins=[0, 20, 30, 40,50,60, float('inf')],labels=[0,1,2,3,4,5])\n    df['FCVC_Cat'] = pd.cut(df['FCVC'], bins=[1,2,3,4,5, float('inf')],labels=[1,2,3,4,5])\n    df['NCP_Cat'] = pd.cut(df['NCP'], bins=[1,2,3,4,5, float('inf')],labels=[1,2,3,4,5])\n    df['CH2O_Cat'] = pd.cut(df['CH2O'], bins=[0, 1, 2, 3,4, float('inf')],labels=[0,1,2,3,4])\n    df['FAF_Cat'] = pd.cut(df['FAF'], bins=[0, 0.5, 1.0, 1.5, 2.5, 3.5, float('inf')],labels=[0,1,2,3,4,5])\n    df['TUE_Cat'] = pd.cut(df['TUE'], bins=[0, 0.5, 1.0, 1.5, 2, 3, float('inf')],labels=[0,1,2,3,4,5])\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.431269Z","iopub.execute_input":"2024-02-05T22:05:47.431802Z","iopub.status.idle":"2024-02-05T22:05:47.443831Z","shell.execute_reply.started":"2024-02-05T22:05:47.431767Z","shell.execute_reply":"2024-02-05T22:05:47.44257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ord_feature(train_df)\nord_feature(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.446009Z","iopub.execute_input":"2024-02-05T22:05:47.446511Z","iopub.status.idle":"2024-02-05T22:05:47.513387Z","shell.execute_reply.started":"2024-02-05T22:05:47.446468Z","shell.execute_reply":"2024-02-05T22:05:47.511009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill(df,col): \n    minm=df[col].min()\n    #print(minm)\n    df[col]=df[col].fillna(minm)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.514605Z","iopub.execute_input":"2024-02-05T22:05:47.514949Z","iopub.status.idle":"2024-02-05T22:05:47.520905Z","shell.execute_reply.started":"2024-02-05T22:05:47.514921Z","shell.execute_reply":"2024-02-05T22:05:47.51989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in train_df.columns:\n    fill(train_df,c)\nfor c in test_df.columns:\n    fill(test_df,c)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.522138Z","iopub.execute_input":"2024-02-05T22:05:47.523051Z","iopub.status.idle":"2024-02-05T22:05:47.651083Z","shell.execute_reply.started":"2024-02-05T22:05:47.523019Z","shell.execute_reply":"2024-02-05T22:05:47.650166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catcol=[c for c in train_df.columns if train_df[c].dtype=='category']\n#print(catcol)\ntrain_df[catcol]=train_df[catcol].astype(int)\n#print(train_df.dtypes)\ntest_df[catcol]=test_df[catcol].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.652221Z","iopub.execute_input":"2024-02-05T22:05:47.653115Z","iopub.status.idle":"2024-02-05T22:05:47.666316Z","shell.execute_reply.started":"2024-02-05T22:05:47.653081Z","shell.execute_reply":"2024-02-05T22:05:47.664966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split data into train and val set\nX_train,X_test,y_train,y_test=train_test_split(train_df.drop(['id','NObeyesdad','y','Data Type'],axis=1),train_df['y'],test_size=0.2,random_state=42)\nX_train.shape, y_train.shape, X_test.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.667736Z","iopub.execute_input":"2024-02-05T22:05:47.668077Z","iopub.status.idle":"2024-02-05T22:05:47.696354Z","shell.execute_reply.started":"2024-02-05T22:05:47.668049Z","shell.execute_reply":"2024-02-05T22:05:47.695238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfor colname in X_train.select_dtypes(['object','bool']).columns:\n    X_train[colname]=LabelEncoder().fit_transform(X_train[colname])\n\nfor colname in train_df.select_dtypes(['object','bool']).columns:\n    train_df[colname]=LabelEncoder().fit_transform(train_df[colname])\n\nfor colname in X_test.select_dtypes(['object','bool']).columns:\n    X_test[colname]=LabelEncoder().fit_transform(X_test[colname])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.697701Z","iopub.execute_input":"2024-02-05T22:05:47.698563Z","iopub.status.idle":"2024-02-05T22:05:47.834604Z","shell.execute_reply.started":"2024-02-05T22:05:47.698522Z","shell.execute_reply":"2024-02-05T22:05:47.83348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use standard scaler for numeric data transformation\nfrom sklearn.preprocessing import MinMaxScaler\nsc=StandardScaler()\nsc.fit(X_train[numeric_columns])\n\n\nX_train[numeric_columns]=sc.transform(X_train[numeric_columns])\nX_test[numeric_columns]=sc.transform(X_test[numeric_columns])\ntrain_df[numeric_columns]=sc.transform(train_df[numeric_columns])\n\ntrain_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.836142Z","iopub.execute_input":"2024-02-05T22:05:47.836516Z","iopub.status.idle":"2024-02-05T22:05:47.882244Z","shell.execute_reply.started":"2024-02-05T22:05:47.836484Z","shell.execute_reply":"2024-02-05T22:05:47.881318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[numeric_columns].describe().T.style.bar(subset=['mean'],color='#7BCC70')\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.883737Z","iopub.execute_input":"2024-02-05T22:05:47.88436Z","iopub.status.idle":"2024-02-05T22:05:47.929052Z","shell.execute_reply.started":"2024-02-05T22:05:47.884325Z","shell.execute_reply":"2024-02-05T22:05:47.928186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n# <span style=\"color:#094863; font-size: 1%|;\"> Define Baseline Models</span>","metadata":{}},{"cell_type":"code","source":"rand=42\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as catboost\nclass_models = {\n    #Tree\n    'decision_tree':{\n        'model': tree. DecisionTreeClassifier(max_depth=7,\n                                              random_state=rand)\n    },\n    \n    #Nearest Neighbors\n    'knn':{'model': neighbors.KNeighborsClassifier(n_neighbors=7)},\n    \n    #Ensemble Methods\n    'gradient_boosting':{\n        'model':ensemble.\n        GradientBoostingClassifier(n_estimators=210)\n    },\n    \n    'random_forest':{\n        'model':ensemble.RandomForestClassifier(\n            max_depth=11,class_weight='balanced', random_state=rand\n        )\n    },\n    \n    'XGBoost':{\n        'model': xgb.XGBClassifier(\n            max_depth=7,class_weight='balanced',eval_metric = 'mlogloss', random_state=rand\n        )\n    },\n    \n    'LightGBM':{\n        'model':lgb.LGBMClassifier(\n            num_leaves=35,max_depth=7,class_weight='balanced', random_state=rand\n        )\n    },\n    \n    'CatBoost':{\n        'model': catboost.CatBoostClassifier(\n                iterations=100, depth=6, learning_rate=0.1,\n                   loss_function='MultiClass', verbose=False\n        )\n    }\n\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.930503Z","iopub.execute_input":"2024-02-05T22:05:47.931084Z","iopub.status.idle":"2024-02-05T22:05:47.943224Z","shell.execute_reply.started":"2024-02-05T22:05:47.931051Z","shell.execute_reply":"2024-02-05T22:05:47.942102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n## <span style=\"color:#094863; font-size: 1%|;\"> Training And Inference</span>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfor model_name, model_info in class_models.items():\n    fitted_model = model_info['model'].fit(X_train, y_train)\n    y_train_pred = fitted_model.predict(X_train)\n    y_test_pred = fitted_model.predict(X_test)\n    \n    model_info['fitted'] = fitted_model\n    model_info['preds'] = y_test_pred\n    model_info['Accuracy_train'] = metrics.accuracy_score(y_train, y_train_pred)\n    model_info['Accuracy_test'] = metrics.accuracy_score(y_test, y_test_pred)\n    model_info['Recall_train'] = metrics.recall_score(y_train, y_train_pred, average='macro')\n    model_info['Recall_test'] = metrics.recall_score(y_test, y_test_pred, average='macro')\n    \n    # For models supporting predict_proba, calculate additional metrics\n    if hasattr(fitted_model, \"predict_proba\"):\n        y_test_prob = fitted_model.predict_proba(X_test)\n        # ROC AUC calculation for multi-class requires binarized labels\n        y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n        if y_test_binarized.shape[1] == 1:  # Binarize returns a single column for two classes\n            y_test_binarized = np.hstack((1 - y_test_binarized, y_test_binarized))\n        model_info['ROC_AUC_test'] = metrics.roc_auc_score(y_test_binarized, y_test_prob, multi_class='ovr', average='macro')\n    else:\n        model_info['ROC_AUC_test'] = np.nan\n\n    model_info['F1_test'] = metrics.f1_score(y_test, y_test_pred, average='macro')\n    model_info['MCC_test'] = metrics.matthews_corrcoef(y_test, y_test_pred)\n\n# Create a DataFrame to display metrics\nclass_metrics = pd.DataFrame.from_dict(\n    class_models, orient='index',\n    columns=['Accuracy_train', 'Accuracy_test', 'Recall_train', 'Recall_test', 'ROC_AUC_test', 'F1_test', 'MCC_test']\n)\n\n# Display the metrics, sorted by ROC_AUC_test score\ndisplay = class_metrics.sort_values(by='ROC_AUC_test', ascending=False).style.format(\"{:.3f}\").background_gradient(cmap='plasma', low=1, high=0.1, subset=['Accuracy_train', 'Accuracy_test']).background_gradient(cmap='viridis', low=1, high=0.1, subset=['Recall_train', 'Recall_test', 'ROC_AUC_test', 'F1_test', 'MCC_test'])\ndisplay\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:05:47.94506Z","iopub.execute_input":"2024-02-05T22:05:47.945432Z","iopub.status.idle":"2024-02-05T22:06:56.247946Z","shell.execute_reply.started":"2024-02-05T22:05:47.945377Z","shell.execute_reply":"2024-02-05T22:06:56.246661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<strong> From above,it seems that XGBoost is the most succesfull . So we will use it to predict final test data.</strong>","metadata":{}},{"cell_type":"code","source":"#Fit all training data \n\nlgb=LGBMClassifier(\n            num_leaves=35,max_depth=7,class_weight='balanced', random_state=rand\n        )\nlgb.fit(train_df.drop(['id','NObeyesdad','y','Data Type'],axis=1),train_df['y'])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:06:56.249894Z","iopub.execute_input":"2024-02-05T22:06:56.250333Z","iopub.status.idle":"2024-02-05T22:06:59.820306Z","shell.execute_reply.started":"2024-02-05T22:06:56.250293Z","shell.execute_reply":"2024-02-05T22:06:59.819095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_skl(x, y, folds, how='log'):\n    n_folds = len(folds)\n    oof = np.zeros((len(y), ))\n    preds = np.zeros((len(y),))\n    \n    print('='*30)\n    for idx in range(n_folds):\n        print(\"FOLD:\", idx)\n        tr_idx, val_idx = folds[idx]\n        xt, yt = x[tr_idx], y[tr_idx]\n        xv, yv = x[val_idx], y[val_idx]\n        \n        elif how == 'xgb':\n            model = xgb.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,class_weight='balanced',eval_metric = 'mlogloss',subsample=0.9,colsample_bytree=0.85)\n        elif how == 'xgb1':\n            model = xgb.XGBClassifier(class_weight='balanced',eval_metric = 'mlogloss')\n        elif how =='lgb':\n            model = lgb.LGBMClassifier(max_depth=3)\n        elif how =='ctb':\n            model = ctb.CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1,\n                   loss_function='MultiClass', verbose=False)\n        elif how == 'mlp':\n            model = MLPClassifier(hidden_layer_sizes=(100,100,),\n                                  random_state=777, max_iter=300)\n        elif how == 'tree':\n            model = DecisionTreeClassifier(max_depth=5) \n        else: \n            model = AdaBoostClassifier( RandomForestClassifier(n_estimators=100, max_depth=4) )\n        #\n        model.fit(xt, yt)\n        \n        #\n        oof[val_idx] =   model.predict_proba(xv)  \n        preds +=  model.predict_proba(xe) /n_folds\n        #\n        print('='*30)\n    return oof, preds\n#===================","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train_df.drop(['id','NObeyesdad','y','Data Type'],axis=1)\ny=train_df['y']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\nFOLDS = list(skf.split(X))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n## <span style=\"color:#094863; font-size: 1%|;\"> Prediction and Submission</span>","metadata":{}},{"cell_type":"code","source":"for colname in test_df.select_dtypes(['object','bool']).columns:\n    test_df[colname]=LabelEncoder().fit_transform(test_df[colname])\n\ntest_df[numeric_columns]=sc.transform(test_df[numeric_columns])\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:06:59.822012Z","iopub.execute_input":"2024-02-05T22:06:59.822366Z","iopub.status.idle":"2024-02-05T22:06:59.896117Z","shell.execute_reply.started":"2024-02-05T22:06:59.822335Z","shell.execute_reply":"2024-02-05T22:06:59.894804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:06:59.897722Z","iopub.execute_input":"2024-02-05T22:06:59.898158Z","iopub.status.idle":"2024-02-05T22:06:59.908035Z","shell.execute_reply.started":"2024-02-05T22:06:59.898119Z","shell.execute_reply":"2024-02-05T22:06:59.906744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:06:59.909653Z","iopub.execute_input":"2024-02-05T22:06:59.910077Z","iopub.status.idle":"2024-02-05T22:06:59.923116Z","shell.execute_reply.started":"2024-02-05T22:06:59.910038Z","shell.execute_reply":"2024-02-05T22:06:59.921915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission['y_test_pred'] = class_models['XGBoost']['model'].predict(test_df.drop(['id','Data Type'],axis=1))\nsubmission['y_test_pred'] = lgb.predict(test_df.drop(['id','Data Type'],axis=1))","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:06:59.924973Z","iopub.execute_input":"2024-02-05T22:06:59.92564Z","iopub.status.idle":"2024-02-05T22:07:00.7386Z","shell.execute_reply.started":"2024-02-05T22:06:59.925596Z","shell.execute_reply":"2024-02-05T22:07:00.737678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:07:00.740351Z","iopub.execute_input":"2024-02-05T22:07:00.741207Z","iopub.status.idle":"2024-02-05T22:07:00.753866Z","shell.execute_reply.started":"2024-02-05T22:07:00.741166Z","shell.execute_reply":"2024-02-05T22:07:00.752705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re map the categories\nnumeric_to_category={v:k for k,v in category_mapping.items()}\nsubmission['NObeyesdad']=submission['y_test_pred'].map(numeric_to_category)\nsubmission.drop(['y_test_pred'],axis=1).head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:07:00.755644Z","iopub.execute_input":"2024-02-05T22:07:00.756137Z","iopub.status.idle":"2024-02-05T22:07:00.776008Z","shell.execute_reply.started":"2024-02-05T22:07:00.756098Z","shell.execute_reply":"2024-02-05T22:07:00.77467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.drop(['y_test_pred'],axis=1).to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T22:07:00.77763Z","iopub.execute_input":"2024-02-05T22:07:00.778507Z","iopub.status.idle":"2024-02-05T22:07:00.818171Z","shell.execute_reply.started":"2024-02-05T22:07:00.778467Z","shell.execute_reply":"2024-02-05T22:07:00.816964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#D2222D solid;padding: 15px;background-color:#ffffff00;font-size:100%;text-align:left\">\n\n## <span style=\"color:#094863; font-size: 1%|;\"> Thank You</span>","metadata":{}}]}